# Build environment

## Prerequisites

* ubuntu:21.10

## Build docker image

We provide DockerFile to build the docker

```bash
docker build -f Alibaba/docker/Dockerfile -t image_name:[tag] .
```

## Start a container

```bash
docker run -tid --net host --name [container_name] -v </path/to/alibaba-submission>:/host/Alibaba image_name:[tag]
docker exec -it [container_name] bash
```

## Install TVM

```bash
DOWNLOAD_PATH=/absolute/path/to/download
INSTALL_PATH=/absolute/path/to/build
bash /host/Alibaba/docker/download_src.sh $DOWNLOAD_PATH
bash /host/Alibaba/docker/build_env.sh $DOWNLOAD_PATH $INSTALL_PATH
```

## Install loadgen

```bash
git clone https://github.com/mlcommons/inference.git
cd inference
git checkout r2.0
cd loadgen
CPLUS_INCLUDE_PATH=/usr/local/lib/python3.9/dist-packages/pybind11/include/ CFLAGS="-std=c++14" python setup.py install
```

# Dataset

The dataset used for this benchmark is [ImageNet 2012](http://image-net.org/challenges/LSVRC/2012/) validation set. You
can get **val_map.txt** in **Alibaba/data_maps/val_map.txt**

# Model

## SinianML/TVM

The Sinian/TVM model `acs_sinianml_acc75.706_is192_p5.297M_f383.205M_fp16_NHWC_B1.so` is provided in `code/model/` directory.

### Optimization

Alibaba's Sinian TVM model is generated by the following steps:

1. Train the model obtained by the Alibaba SinianML framework from scratch;
2. Convert the best model type to `tflite`;
3. Create TVM graph via [```tvm.relay.frontend.from_tflite(...)```](https://tvm.apache.org/docs/reference/api/python/relay/frontend.html#tvm.relay.frontend.from_tflite);
4. Cast the precision from `float32` to `float16`, via [```tvm.relay.transform.ToMixedPrecision('float16')(...)```](https://tvm.apache.org/docs/reference/api/python/relay/transform.html?highlight=tomixedprecision#tvm.relay.transform.ToMixedPrecision);
5. Build the TVM module and save it to `*.so` file;

# Run Resnet50

```bash
cd <path_to_inference_results>/open/Alibaba/code/
# for performance mode
python run.py --config config/performance.yaml  # Edit config/config.yaml if necessary
# for accuracy mode
python run.py --config config/accuracy.yaml  # Edit config/config.yaml if necessary
# get accuracy result
python accuracy-imagenet.py --mlperf-accuracy-file output_logs/mlperf_log_accuracy.json --imagenet-val-file <ILSVRC2012_img_val>/val_map.txt --dtype int32
```

**Note:** *accuracy-imagenet.py* is
in [inference/vision/classification_and_detection/tools/accuracy-imagenet.py](https://github.com/mlcommons/inference/blob/master/vision/classification_and_detection/tools/accuracy-imagenet.py) 