client 2022-02-12 07:59:24,626 [INFO] Sending command to the server: 'mlcommons/power client v3'
client 2022-02-12 07:59:24,634 [INFO] Got response: 'mlcommons/power server v3'
client 2022-02-12 07:59:24,634 [INFO] Sending command to the server: 'stop'
client 2022-02-12 07:59:24,636 [INFO] Got response: 'OK'
client 2022-02-12 07:59:24,637 [INFO] Synchronizing with the server and with ib-01.dc4-in.nvidia.com...
client 2022-02-12 07:59:24,864 [INFO] NTP:offset = 0.002 s, delay = 0.209 s 
client 2022-02-12 07:59:24,865 [INFO] Sending command to the server: 'time'
client 2022-02-12 07:59:24,878 [INFO] Got response: '1644681564.7988772'
client 2022-02-12 07:59:24,879 [INFO] The time difference between the client and the server is within range 66.505 ms..80.173 ms
client 2022-02-12 07:59:24,879 [INFO] Sending command to the server: 'new,,14c0dbd8-40ee-46b9-b7cf-ebc95ffaee77'
client 2022-02-12 07:59:24,896 [INFO] Got response: 'OK 2022-02-12_07-59-24,d9247b5a-d7aa-4148-8dbc-6be200b19f3c'
client 2022-02-12 07:59:24,896 [INFO] Session id is '2022-02-12_07-59-24'
client 2022-02-12 07:59:24,897 [INFO] Sources: {"sources": {"__init__.py": "da39a3ee5e6b4b0d3255bfef95601890afd80709", "client.py": "33ca4f26368777ac06e01f9567b714a4b8063886", "lib/__init__.py": "da39a3ee5e6b4b0d3255bfef95601890afd80709", "lib/client.py": "4c2b78fb4849a7e5b584ef792d82aaed20b17f57", "lib/common.py": "624d0c0acc7c39aaff3674f0b99d6a09da53d1dc", "lib/external/__init__.py": "da39a3ee5e6b4b0d3255bfef95601890afd80709", "lib/external/ntplib.py": "4da8f970656505a40483206ef2b5d3dd5e81711d", "lib/server.py": "59c9fb92908260d3e9f81a895c7aa009742275e4", "lib/source_hashes.py": "60a2e02193209e8d392803326208d5466342da18", "lib/summary.py": "aa92f0a3f975eecd44d3c0cd0236342ccc9f941d", "lib/time_sync.py": "3210db56eb0ff0df57bf4293dc4d4b03fffd46f1", "server.py": "c3f90f2f7eeb4db30727556d0c815ebc89b3d28b", "tests/unit/__init__.py": "da39a3ee5e6b4b0d3255bfef95601890afd80709", "tests/unit/test_server.py": "99ae15aef722f2000ee6ed1ae1523637bf1ae42b", "tests/unit/test_source_hashes.py": "00468a2907583c593e6574a1f6b404e4651c221a"}, "modules": {"ptd_client_server.lib.client": "lib/client.py", "ptd_client_server.lib.common": "lib/common.py", "ptd_client_server.lib.external.ntplib": "lib/external/ntplib.py", "ptd_client_server.lib.source_hashes": "lib/source_hashes.py", "ptd_client_server.lib.summary": "lib/summary.py", "ptd_client_server.lib.time_sync": "lib/time_sync.py"}}
client 2022-02-12 07:59:24,900 [INFO] Running workload in ranging mode
client 2022-02-12 07:59:24,900 [INFO] Synchronizing with the server and with ib-01.dc4-in.nvidia.com...
client 2022-02-12 07:59:25,115 [INFO] NTP:offset = 0.002 s, delay = 0.209 s 
client 2022-02-12 07:59:25,116 [INFO] Sending command to the server: 'time'
client 2022-02-12 07:59:25,125 [INFO] Got response: '1644681565.0387309'
client 2022-02-12 07:59:25,125 [INFO] The time difference between the client and the server is within range 77.332 ms..86.783 ms
client 2022-02-12 07:59:25,125 [INFO] Sending command to the server: 'session,2022-02-12_07-59-24,start,ranging'
client 2022-02-12 07:59:53,903 [INFO] Got response: 'OK'
client 2022-02-12 07:59:53,904 [INFO] Running the workload 'LOG_DIR=/home/scratch.mlperf_inf_ci/mlPerf/L2/XavierNX_MaxQ-Computelab-XavierNX-MaxQ-L2-41-2022-02-12-02-06-01-UTC/mlperf-inference/closed/NVIDIA/build/power_logs_temp python3 code/main.py --benchmarks=ssd-mobilenet --scenarios=MultiStream --test_mode=PerformanceOnly --config_ver=maxq --action="run_harness" \\\n\t\t2>&1 | tee -a /home/scratch.mlperf_inf_ci/mlPerf/L2/XavierNX_MaxQ-Computelab-XavierNX-MaxQ-L2-41-2022-02-12-02-06-01-UTC/mlperf-inference/closed/NVIDIA/build/power_logs/2022.02.12-07.59.05/stdout.txt \\\n\t\t&& if [ ! -d /home/scratch.mlperf_inf_ci/mlPerf/L2/XavierNX_MaxQ-Computelab-XavierNX-MaxQ-L2-41-2022-02-12-02-06-01-UTC/mlperf-inference/closed/NVIDIA/build/power_logs/2022.02.12-07.59.05/ranging_tmp ]; \\\n\t\t\tthen mkdir /home/scratch.mlperf_inf_ci/mlPerf/L2/XavierNX_MaxQ-Computelab-XavierNX-MaxQ-L2-41-2022-02-12-02-06-01-UTC/mlperf-inference/closed/NVIDIA/build/power_logs/2022.02.12-07.59.05/ranging_tmp \\\n\t\t\t\t&& mv /home/scratch.mlperf_inf_ci/mlPerf/L2/XavierNX_MaxQ-Computelab-XavierNX-MaxQ-L2-41-2022-02-12-02-06-01-UTC/mlperf-inference/closed/NVIDIA/build/power_logs_temp/* /home/scratch.mlperf_inf_ci/mlPerf/L2/XavierNX_MaxQ-Computelab-XavierNX-MaxQ-L2-41-2022-02-12-02-06-01-UTC/mlperf-inference/closed/NVIDIA/build/power_logs/2022.02.12-07.59.05/ranging_tmp/ \\\n\t\t\t\t&& cp -v /home/scratch.mlperf_inf_ci/mlPerf/L2/XavierNX_MaxQ-Computelab-XavierNX-MaxQ-L2-41-2022-02-12-02-06-01-UTC/mlperf-inference/closed/NVIDIA/build/power_logs/2022.02.12-07.59.05/ranging_tmp/*/*/*/mlperf_log_detail.txt /home/scratch.mlperf_inf_ci/mlPerf/L2/XavierNX_MaxQ-Computelab-XavierNX-MaxQ-L2-41-2022-02-12-02-06-01-UTC/mlperf-inference/closed/NVIDIA/build/power_logs_temp/ \\\n\t\t\t\t&& cp -v /home/scratch.mlperf_inf_ci/mlPerf/L2/XavierNX_MaxQ-Computelab-XavierNX-MaxQ-L2-41-2022-02-12-02-06-01-UTC/mlperf-inference/closed/NVIDIA/build/power_logs/2022.02.12-07.59.05/ranging_tmp/*/*/*/mlperf_log_summary.txt /home/scratch.mlperf_inf_ci/mlPerf/L2/XavierNX_MaxQ-Computelab-XavierNX-MaxQ-L2-41-2022-02-12-02-06-01-UTC/mlperf-inference/closed/NVIDIA/build/power_logs_temp/; \\\n\t\t\telse mkdir /home/scratch.mlperf_inf_ci/mlPerf/L2/XavierNX_MaxQ-Computelab-XavierNX-MaxQ-L2-41-2022-02-12-02-06-01-UTC/mlperf-inference/closed/NVIDIA/build/power_logs/2022.02.12-07.59.05/testing_tmp \\\n\t\t\t\t&& mv /home/scratch.mlperf_inf_ci/mlPerf/L2/XavierNX_MaxQ-Computelab-XavierNX-MaxQ-L2-41-2022-02-12-02-06-01-UTC/mlperf-inference/closed/NVIDIA/build/power_logs_temp/* /home/scratch.mlperf_inf_ci/mlPerf/L2/XavierNX_MaxQ-Computelab-XavierNX-MaxQ-L2-41-2022-02-12-02-06-01-UTC/mlperf-inference/closed/NVIDIA/build/power_logs/2022.02.12-07.59.05/testing_tmp/ \\\n\t\t\t\t&& cp -v /home/scratch.mlperf_inf_ci/mlPerf/L2/XavierNX_MaxQ-Computelab-XavierNX-MaxQ-L2-41-2022-02-12-02-06-01-UTC/mlperf-inference/closed/NVIDIA/build/power_logs/2022.02.12-07.59.05/testing_tmp/*/*/*/mlperf_log_detail.txt /home/scratch.mlperf_inf_ci/mlPerf/L2/XavierNX_MaxQ-Computelab-XavierNX-MaxQ-L2-41-2022-02-12-02-06-01-UTC/mlperf-inference/closed/NVIDIA/build/power_logs_temp/ \\\n\t\t\t\t&& cp -v /home/scratch.mlperf_inf_ci/mlPerf/L2/XavierNX_MaxQ-Computelab-XavierNX-MaxQ-L2-41-2022-02-12-02-06-01-UTC/mlperf-inference/closed/NVIDIA/build/power_logs/2022.02.12-07.59.05/testing_tmp/*/*/*/mlperf_log_summary.txt /home/scratch.mlperf_inf_ci/mlPerf/L2/XavierNX_MaxQ-Computelab-XavierNX-MaxQ-L2-41-2022-02-12-02-06-01-UTC/mlperf-inference/closed/NVIDIA/build/power_logs_temp/; fi'
client 2022-02-12 08:35:50,043 [INFO] Sending command to the server: 'session,2022-02-12_07-59-24,stop,ranging'
client 2022-02-12 08:36:00,104 [INFO] Got response: 'OK'
client 2022-02-12 08:36:00,134 [INFO] Copying loadgen logs from '/home/scratch.mlperf_inf_ci/mlPerf/L2/XavierNX_MaxQ-Computelab-XavierNX-MaxQ-L2-41-2022-02-12-02-06-01-UTC/mlperf-inference/closed/NVIDIA/build/power_logs_temp' to '/home/scratch.mlperf_inf_ci/mlPerf/L2/XavierNX_MaxQ-Computelab-XavierNX-MaxQ-L2-41-2022-02-12-02-06-01-UTC/mlperf-inference/closed/NVIDIA/build/power_logs/2022.02.12-07.59.05/2022-02-12_07-59-24/ranging'
client 2022-02-12 08:36:00,149 [INFO] Running workload in testing mode
client 2022-02-12 08:36:00,149 [INFO] Synchronizing with the server and with ib-01.dc4-in.nvidia.com...
client 2022-02-12 08:36:00,366 [INFO] NTP:offset = 0.003 s, delay = 0.209 s 
client 2022-02-12 08:36:00,367 [INFO] Sending command to the server: 'time'
client 2022-02-12 08:36:00,372 [INFO] Got response: '1644683760.2971373'
client 2022-02-12 08:36:00,372 [INFO] The time difference between the client and the server is within range 70.042 ms..75.682 ms
client 2022-02-12 08:36:00,373 [INFO] Sending command to the server: 'session,2022-02-12_07-59-24,start,testing'
client 2022-02-12 08:36:13,921 [INFO] Got response: 'OK'
client 2022-02-12 08:36:13,922 [INFO] Running the workload 'LOG_DIR=/home/scratch.mlperf_inf_ci/mlPerf/L2/XavierNX_MaxQ-Computelab-XavierNX-MaxQ-L2-41-2022-02-12-02-06-01-UTC/mlperf-inference/closed/NVIDIA/build/power_logs_temp python3 code/main.py --benchmarks=ssd-mobilenet --scenarios=MultiStream --test_mode=PerformanceOnly --config_ver=maxq --action="run_harness" \\\n\t\t2>&1 | tee -a /home/scratch.mlperf_inf_ci/mlPerf/L2/XavierNX_MaxQ-Computelab-XavierNX-MaxQ-L2-41-2022-02-12-02-06-01-UTC/mlperf-inference/closed/NVIDIA/build/power_logs/2022.02.12-07.59.05/stdout.txt \\\n\t\t&& if [ ! -d /home/scratch.mlperf_inf_ci/mlPerf/L2/XavierNX_MaxQ-Computelab-XavierNX-MaxQ-L2-41-2022-02-12-02-06-01-UTC/mlperf-inference/closed/NVIDIA/build/power_logs/2022.02.12-07.59.05/ranging_tmp ]; \\\n\t\t\tthen mkdir /home/scratch.mlperf_inf_ci/mlPerf/L2/XavierNX_MaxQ-Computelab-XavierNX-MaxQ-L2-41-2022-02-12-02-06-01-UTC/mlperf-inference/closed/NVIDIA/build/power_logs/2022.02.12-07.59.05/ranging_tmp \\\n\t\t\t\t&& mv /home/scratch.mlperf_inf_ci/mlPerf/L2/XavierNX_MaxQ-Computelab-XavierNX-MaxQ-L2-41-2022-02-12-02-06-01-UTC/mlperf-inference/closed/NVIDIA/build/power_logs_temp/* /home/scratch.mlperf_inf_ci/mlPerf/L2/XavierNX_MaxQ-Computelab-XavierNX-MaxQ-L2-41-2022-02-12-02-06-01-UTC/mlperf-inference/closed/NVIDIA/build/power_logs/2022.02.12-07.59.05/ranging_tmp/ \\\n\t\t\t\t&& cp -v /home/scratch.mlperf_inf_ci/mlPerf/L2/XavierNX_MaxQ-Computelab-XavierNX-MaxQ-L2-41-2022-02-12-02-06-01-UTC/mlperf-inference/closed/NVIDIA/build/power_logs/2022.02.12-07.59.05/ranging_tmp/*/*/*/mlperf_log_detail.txt /home/scratch.mlperf_inf_ci/mlPerf/L2/XavierNX_MaxQ-Computelab-XavierNX-MaxQ-L2-41-2022-02-12-02-06-01-UTC/mlperf-inference/closed/NVIDIA/build/power_logs_temp/ \\\n\t\t\t\t&& cp -v /home/scratch.mlperf_inf_ci/mlPerf/L2/XavierNX_MaxQ-Computelab-XavierNX-MaxQ-L2-41-2022-02-12-02-06-01-UTC/mlperf-inference/closed/NVIDIA/build/power_logs/2022.02.12-07.59.05/ranging_tmp/*/*/*/mlperf_log_summary.txt /home/scratch.mlperf_inf_ci/mlPerf/L2/XavierNX_MaxQ-Computelab-XavierNX-MaxQ-L2-41-2022-02-12-02-06-01-UTC/mlperf-inference/closed/NVIDIA/build/power_logs_temp/; \\\n\t\t\telse mkdir /home/scratch.mlperf_inf_ci/mlPerf/L2/XavierNX_MaxQ-Computelab-XavierNX-MaxQ-L2-41-2022-02-12-02-06-01-UTC/mlperf-inference/closed/NVIDIA/build/power_logs/2022.02.12-07.59.05/testing_tmp \\\n\t\t\t\t&& mv /home/scratch.mlperf_inf_ci/mlPerf/L2/XavierNX_MaxQ-Computelab-XavierNX-MaxQ-L2-41-2022-02-12-02-06-01-UTC/mlperf-inference/closed/NVIDIA/build/power_logs_temp/* /home/scratch.mlperf_inf_ci/mlPerf/L2/XavierNX_MaxQ-Computelab-XavierNX-MaxQ-L2-41-2022-02-12-02-06-01-UTC/mlperf-inference/closed/NVIDIA/build/power_logs/2022.02.12-07.59.05/testing_tmp/ \\\n\t\t\t\t&& cp -v /home/scratch.mlperf_inf_ci/mlPerf/L2/XavierNX_MaxQ-Computelab-XavierNX-MaxQ-L2-41-2022-02-12-02-06-01-UTC/mlperf-inference/closed/NVIDIA/build/power_logs/2022.02.12-07.59.05/testing_tmp/*/*/*/mlperf_log_detail.txt /home/scratch.mlperf_inf_ci/mlPerf/L2/XavierNX_MaxQ-Computelab-XavierNX-MaxQ-L2-41-2022-02-12-02-06-01-UTC/mlperf-inference/closed/NVIDIA/build/power_logs_temp/ \\\n\t\t\t\t&& cp -v /home/scratch.mlperf_inf_ci/mlPerf/L2/XavierNX_MaxQ-Computelab-XavierNX-MaxQ-L2-41-2022-02-12-02-06-01-UTC/mlperf-inference/closed/NVIDIA/build/power_logs/2022.02.12-07.59.05/testing_tmp/*/*/*/mlperf_log_summary.txt /home/scratch.mlperf_inf_ci/mlPerf/L2/XavierNX_MaxQ-Computelab-XavierNX-MaxQ-L2-41-2022-02-12-02-06-01-UTC/mlperf-inference/closed/NVIDIA/build/power_logs_temp/; fi'
client 2022-02-12 09:12:40,507 [INFO] Sending command to the server: 'session,2022-02-12_07-59-24,stop,testing'
client 2022-02-12 09:12:50,615 [INFO] Got response: 'OK'
client 2022-02-12 09:12:50,648 [INFO] Copying loadgen logs from '/home/scratch.mlperf_inf_ci/mlPerf/L2/XavierNX_MaxQ-Computelab-XavierNX-MaxQ-L2-41-2022-02-12-02-06-01-UTC/mlperf-inference/closed/NVIDIA/build/power_logs_temp' to '/home/scratch.mlperf_inf_ci/mlPerf/L2/XavierNX_MaxQ-Computelab-XavierNX-MaxQ-L2-41-2022-02-12-02-06-01-UTC/mlperf-inference/closed/NVIDIA/build/power_logs/2022.02.12-07.59.05/2022-02-12_07-59-24/run_1'
client 2022-02-12 09:12:50,663 [INFO] Done runs
