client 2022-02-18 22:33:49,961 [INFO] Sending command to the server: 'mlcommons/power client v3'
client 2022-02-18 22:33:49,963 [INFO] Got response: 'mlcommons/power server v3'
client 2022-02-18 22:33:49,963 [INFO] Synchronizing with the server and with time.google.com...
client 2022-02-18 22:33:50,046 [INFO] NTP:offset = 0.004 s, delay = 0.074 s 
client 2022-02-18 22:33:50,047 [INFO] Sending command to the server: 'time'
client 2022-02-18 22:33:50,048 [INFO] Got response: '1645245230.0516772'
client 2022-02-18 22:33:50,048 [INFO] The time difference between the client and the server is within range -4.621 ms..-3.356 ms
client 2022-02-18 22:33:50,048 [INFO] Sending command to the server: 'new,,d3efa5df-510e-401c-b77c-003a00bafa2b'
client 2022-02-18 22:33:50,049 [INFO] Got response: 'OK 2022-02-18_22-33-50,010f01ca-2ef1-4689-8f2b-f30a52046930'
client 2022-02-18 22:33:50,049 [INFO] Session id is '2022-02-18_22-33-50'
client 2022-02-18 22:33:50,050 [INFO] Sources: {"sources": {"__init__.py": "da39a3ee5e6b4b0d3255bfef95601890afd80709", "client.py": "33ca4f26368777ac06e01f9567b714a4b8063886", "lib/__init__.py": "da39a3ee5e6b4b0d3255bfef95601890afd80709", "lib/client.py": "4c2b78fb4849a7e5b584ef792d82aaed20b17f57", "lib/common.py": "624d0c0acc7c39aaff3674f0b99d6a09da53d1dc", "lib/external/__init__.py": "da39a3ee5e6b4b0d3255bfef95601890afd80709", "lib/external/ntplib.py": "4da8f970656505a40483206ef2b5d3dd5e81711d", "lib/server.py": "59c9fb92908260d3e9f81a895c7aa009742275e4", "lib/source_hashes.py": "60a2e02193209e8d392803326208d5466342da18", "lib/summary.py": "aa92f0a3f975eecd44d3c0cd0236342ccc9f941d", "lib/time_sync.py": "3210db56eb0ff0df57bf4293dc4d4b03fffd46f1", "server.py": "c3f90f2f7eeb4db30727556d0c815ebc89b3d28b", "tests/unit/__init__.py": "da39a3ee5e6b4b0d3255bfef95601890afd80709", "tests/unit/test_server.py": "99ae15aef722f2000ee6ed1ae1523637bf1ae42b", "tests/unit/test_source_hashes.py": "00468a2907583c593e6574a1f6b404e4651c221a"}, "modules": {"ptd_client_server.lib.client": "lib/client.py", "ptd_client_server.lib.common": "lib/common.py", "ptd_client_server.lib.external.ntplib": "lib/external/ntplib.py", "ptd_client_server.lib.source_hashes": "lib/source_hashes.py", "ptd_client_server.lib.summary": "lib/summary.py", "ptd_client_server.lib.time_sync": "lib/time_sync.py"}}
client 2022-02-18 22:33:50,050 [INFO] Running workload in ranging mode
client 2022-02-18 22:33:50,050 [INFO] Synchronizing with the server and with time.google.com...
client 2022-02-18 22:33:50,159 [INFO] NTP:offset = 0.003 s, delay = 0.098 s 
client 2022-02-18 22:33:50,159 [INFO] Sending command to the server: 'time'
client 2022-02-18 22:33:50,161 [INFO] Got response: '1645245230.1644921'
client 2022-02-18 22:33:50,161 [INFO] The time difference between the client and the server is within range -4.616 ms..-3.373 ms
client 2022-02-18 22:33:50,161 [INFO] Sending command to the server: 'session,2022-02-18_22-33-50,start,ranging'
client 2022-02-18 22:34:27,870 [INFO] Got response: 'OK'
client 2022-02-18 22:34:27,870 [INFO] Running the workload 'sleep 90; numactl --localalloc ck benchmark program:packed-bert-qaic-loadgen --env.CK_SILENT_MODE=YES --skip_print_timers --dep_add_tags.compiler=gcc --dep_add_tags.python=v3 --dep_add_tags.weights=bert-99.pcie.16nsp.offline,bert-99,quantization.calibration  --dep_add_tags.dataset-tokenized=dataset,squad,tokenized,raw --env.ML_MODEL_MODEL_NAME=bert-99 --env.CK_LOADGEN_DATASET_SIZE=10833 --env.CK_LOADGEN_BUFFER_SIZE=10833 --env.CK_ENV_NUM_SETUP_THREADS=2 --env.CK_ENV_QAIC_INPUT_SELECT=0 --env.CK_ENV_QAIC_DEVICE_IDS=0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15 --env.CK_ENV_QAIC_QUEUE_LENGTH=4 --env.CK_ENV_QAIC_THREADS_PER_QUEUE=4 --env.CK_ENV_QAIC_ACTIVATION_COUNT=8 --env.CK_ENV_QAIC_MODEL_BATCH_SIZE=1024 --env.QAIC_BYPASS_PPP=enable --env.CK_VERBOSE=0 --env.CK_EXTRA_COMPILER_DEPS1=-march=znver2 --env.CK_EXTRA_COMPILER_DEPS2=-DENABLE_ZEN2 --env.CK_EXTRA_COMPILER_DEPS3=-DG292_CONFA  --env.ML_MODEL_MODEL_NAME=bert --env.CK_ENV_QAIC_SKIP_STAGE=convert --env.CK_LOADGEN_SCENARIO=Server --env.CK_ENV_QAIC_MAX_WAIT_ABS=50000 --env.CK_EXTRA_COMPILER_DEPS4=-DSERVER_MODE --env.CK_LOADGEN_TARGET_QPS=9600  --env.CK_LOADGEN_TARGET_QPS=9600  --env.CK_LOADGEN_MODE=PerformanceOnly --speed --skip_stat_analysis --process_multi_keys --repetitions=1 --record --record_repo=local --record_uoa=mlperf_v2.0-closed-g292_z43_q16e-qaic-v1.6.80-aic100-bert-99-server-performance-target_qps.9600-fan_raw.100-vc.10-power.workload --tags=mlperf,division.closed,platform.g292_z43_q16e,inference_engine.qaic,inference_engine_version.v1.6.80,inference_engine_backend.aic100,scenario.server,mode.performance,buffer_size.10833,workload.bert-99,preprocessed_using.tensorflow,input_select.0,queue_length.4,task.bert-question-answering,threads_per_queue.4,vc.10,power.workload "@@@{\'meta\': {\'ck_benchmark_program\': \'sleep 90; numactl --localalloc ck benchmark program:packed-bert-qaic-loadgen --env.CK_SILENT_MODE=YES --skip_print_timers --dep_add_tags.compiler=gcc --dep_add_tags.python=v3 --dep_add_tags.weights=bert-99.pcie.16nsp.offline,bert-99,quantization.calibration  --dep_add_tags.dataset-tokenized=dataset,squad,tokenized,raw --env.ML_MODEL_MODEL_NAME=bert-99 --env.CK_LOADGEN_DATASET_SIZE=10833 --env.CK_LOADGEN_BUFFER_SIZE=10833 --env.CK_ENV_NUM_SETUP_THREADS=2 --env.CK_ENV_QAIC_INPUT_SELECT=0 --env.CK_ENV_QAIC_DEVICE_IDS=0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15 --env.CK_ENV_QAIC_QUEUE_LENGTH=4 --env.CK_ENV_QAIC_THREADS_PER_QUEUE=4 --env.CK_ENV_QAIC_ACTIVATION_COUNT=8 --env.CK_ENV_QAIC_MODEL_BATCH_SIZE=1024 --env.QAIC_BYPASS_PPP=enable --env.CK_VERBOSE=0 --env.CK_EXTRA_COMPILER_DEPS1=-march=znver2 --env.CK_EXTRA_COMPILER_DEPS2=-DENABLE_ZEN2 --env.CK_EXTRA_COMPILER_DEPS3=-DG292_CONFA  --env.ML_MODEL_MODEL_NAME=bert --env.CK_ENV_QAIC_SKIP_STAGE=convert --env.CK_LOADGEN_SCENARIO=Server --env.CK_ENV_QAIC_MAX_WAIT_ABS=50000 --env.CK_EXTRA_COMPILER_DEPS4=-DSERVER_MODE --env.CK_LOADGEN_TARGET_QPS=9600  --env.CK_LOADGEN_TARGET_QPS=9600  --env.CK_LOADGEN_MODE=PerformanceOnly --speed --skip_stat_analysis --process_multi_keys --repetitions=1 --record --record_repo=local --record_uoa=mlperf_v2.0-closed-g292_z43_q16e-qaic-v1.6.80-aic100-bert-99-server-performance-target_qps.9600-fan_raw.100-vc.10-power.workload --tags=mlperf,division.closed,platform.g292_z43_q16e,inference_engine.qaic,inference_engine_version.v1.6.80,inference_engine_backend.aic100,scenario.server,mode.performance,buffer_size.10833,workload.bert-99,preprocessed_using.tensorflow,input_select.0,queue_length.4,task.bert-question-answering,threads_per_queue.4,vc.10,power.workload\'}}" && cat `ck find program:packed-bert-qaic-loadgen`/tmp/mlperf_log_summary.txt && mkdir -p "$CK_MLPERF_POWER_CLIENT_LOADGEN_LOGS" && cp "$CK_MLPERF_POWER_CLIENT_LOADGEN_LOGS"/../mlperf_log_* "$CK_MLPERF_POWER_CLIENT_LOADGEN_LOGS"/'
client 2022-02-18 22:48:08,608 [INFO] Sending command to the server: 'session,2022-02-18_22-33-50,stop,ranging'
client 2022-02-18 22:48:18,652 [INFO] Got response: 'OK'
client 2022-02-18 22:48:18,658 [INFO] Copying loadgen logs from '/home/krai/CK_REPOS/ck-qaic/program/packed-bert-qaic-loadgen/tmp/loadgen_logs' to '/home/krai/CK_REPOS/ck-mlperf/program/mlperf-power-client/tmp/2022-02-18_22-33-50/ranging'
client 2022-02-18 22:48:18,659 [INFO] Running workload in testing mode
client 2022-02-18 22:48:18,659 [INFO] Synchronizing with the server and with time.google.com...
client 2022-02-18 22:48:18,767 [INFO] NTP:offset = 0.007 s, delay = 0.097 s 
client 2022-02-18 22:48:18,767 [INFO] Sending command to the server: 'time'
client 2022-02-18 22:48:18,768 [INFO] Got response: '1645246098.7750182'
client 2022-02-18 22:48:18,768 [INFO] The time difference between the client and the server is within range -7.259 ms..-6.459 ms
client 2022-02-18 22:48:18,768 [INFO] Sending command to the server: 'session,2022-02-18_22-33-50,start,testing'
client 2022-02-18 22:48:40,481 [INFO] Got response: 'OK'
client 2022-02-18 22:48:40,481 [INFO] Running the workload 'sleep 90; numactl --localalloc ck benchmark program:packed-bert-qaic-loadgen --env.CK_SILENT_MODE=YES --skip_print_timers --dep_add_tags.compiler=gcc --dep_add_tags.python=v3 --dep_add_tags.weights=bert-99.pcie.16nsp.offline,bert-99,quantization.calibration  --dep_add_tags.dataset-tokenized=dataset,squad,tokenized,raw --env.ML_MODEL_MODEL_NAME=bert-99 --env.CK_LOADGEN_DATASET_SIZE=10833 --env.CK_LOADGEN_BUFFER_SIZE=10833 --env.CK_ENV_NUM_SETUP_THREADS=2 --env.CK_ENV_QAIC_INPUT_SELECT=0 --env.CK_ENV_QAIC_DEVICE_IDS=0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15 --env.CK_ENV_QAIC_QUEUE_LENGTH=4 --env.CK_ENV_QAIC_THREADS_PER_QUEUE=4 --env.CK_ENV_QAIC_ACTIVATION_COUNT=8 --env.CK_ENV_QAIC_MODEL_BATCH_SIZE=1024 --env.QAIC_BYPASS_PPP=enable --env.CK_VERBOSE=0 --env.CK_EXTRA_COMPILER_DEPS1=-march=znver2 --env.CK_EXTRA_COMPILER_DEPS2=-DENABLE_ZEN2 --env.CK_EXTRA_COMPILER_DEPS3=-DG292_CONFA  --env.ML_MODEL_MODEL_NAME=bert --env.CK_ENV_QAIC_SKIP_STAGE=convert --env.CK_LOADGEN_SCENARIO=Server --env.CK_ENV_QAIC_MAX_WAIT_ABS=50000 --env.CK_EXTRA_COMPILER_DEPS4=-DSERVER_MODE --env.CK_LOADGEN_TARGET_QPS=9600  --env.CK_LOADGEN_TARGET_QPS=9600  --env.CK_LOADGEN_MODE=PerformanceOnly --speed --skip_stat_analysis --process_multi_keys --repetitions=1 --record --record_repo=local --record_uoa=mlperf_v2.0-closed-g292_z43_q16e-qaic-v1.6.80-aic100-bert-99-server-performance-target_qps.9600-fan_raw.100-vc.10-power.workload --tags=mlperf,division.closed,platform.g292_z43_q16e,inference_engine.qaic,inference_engine_version.v1.6.80,inference_engine_backend.aic100,scenario.server,mode.performance,buffer_size.10833,workload.bert-99,preprocessed_using.tensorflow,input_select.0,queue_length.4,task.bert-question-answering,threads_per_queue.4,vc.10,power.workload "@@@{\'meta\': {\'ck_benchmark_program\': \'sleep 90; numactl --localalloc ck benchmark program:packed-bert-qaic-loadgen --env.CK_SILENT_MODE=YES --skip_print_timers --dep_add_tags.compiler=gcc --dep_add_tags.python=v3 --dep_add_tags.weights=bert-99.pcie.16nsp.offline,bert-99,quantization.calibration  --dep_add_tags.dataset-tokenized=dataset,squad,tokenized,raw --env.ML_MODEL_MODEL_NAME=bert-99 --env.CK_LOADGEN_DATASET_SIZE=10833 --env.CK_LOADGEN_BUFFER_SIZE=10833 --env.CK_ENV_NUM_SETUP_THREADS=2 --env.CK_ENV_QAIC_INPUT_SELECT=0 --env.CK_ENV_QAIC_DEVICE_IDS=0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15 --env.CK_ENV_QAIC_QUEUE_LENGTH=4 --env.CK_ENV_QAIC_THREADS_PER_QUEUE=4 --env.CK_ENV_QAIC_ACTIVATION_COUNT=8 --env.CK_ENV_QAIC_MODEL_BATCH_SIZE=1024 --env.QAIC_BYPASS_PPP=enable --env.CK_VERBOSE=0 --env.CK_EXTRA_COMPILER_DEPS1=-march=znver2 --env.CK_EXTRA_COMPILER_DEPS2=-DENABLE_ZEN2 --env.CK_EXTRA_COMPILER_DEPS3=-DG292_CONFA  --env.ML_MODEL_MODEL_NAME=bert --env.CK_ENV_QAIC_SKIP_STAGE=convert --env.CK_LOADGEN_SCENARIO=Server --env.CK_ENV_QAIC_MAX_WAIT_ABS=50000 --env.CK_EXTRA_COMPILER_DEPS4=-DSERVER_MODE --env.CK_LOADGEN_TARGET_QPS=9600  --env.CK_LOADGEN_TARGET_QPS=9600  --env.CK_LOADGEN_MODE=PerformanceOnly --speed --skip_stat_analysis --process_multi_keys --repetitions=1 --record --record_repo=local --record_uoa=mlperf_v2.0-closed-g292_z43_q16e-qaic-v1.6.80-aic100-bert-99-server-performance-target_qps.9600-fan_raw.100-vc.10-power.workload --tags=mlperf,division.closed,platform.g292_z43_q16e,inference_engine.qaic,inference_engine_version.v1.6.80,inference_engine_backend.aic100,scenario.server,mode.performance,buffer_size.10833,workload.bert-99,preprocessed_using.tensorflow,input_select.0,queue_length.4,task.bert-question-answering,threads_per_queue.4,vc.10,power.workload\'}}" && cat `ck find program:packed-bert-qaic-loadgen`/tmp/mlperf_log_summary.txt && mkdir -p "$CK_MLPERF_POWER_CLIENT_LOADGEN_LOGS" && cp "$CK_MLPERF_POWER_CLIENT_LOADGEN_LOGS"/../mlperf_log_* "$CK_MLPERF_POWER_CLIENT_LOADGEN_LOGS"/'
client 2022-02-18 23:02:22,511 [INFO] Sending command to the server: 'session,2022-02-18_22-33-50,stop,testing'
client 2022-02-18 23:02:32,538 [INFO] Got response: 'OK'
client 2022-02-18 23:02:32,539 [INFO] Copying loadgen logs from '/home/krai/CK_REPOS/ck-qaic/program/packed-bert-qaic-loadgen/tmp/loadgen_logs' to '/home/krai/CK_REPOS/ck-mlperf/program/mlperf-power-client/tmp/2022-02-18_22-33-50/run_1'
client 2022-02-18 23:02:32,540 [INFO] Done runs
