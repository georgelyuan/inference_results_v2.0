round#1
[2022-02-22 07:49:02,373 __init__.py:185 INFO] Running command: CUDA_VISIBLE_ORDER=PCI_BUS_ID nvidia-smi --query-gpu=gpu_name,pci.device_id,uuid --format=csv
[2022-02-22 07:49:02,393 main.py:760 INFO] Detected System ID: A100-SXM-80GBx1
[2022-02-22 07:49:02,649 main.py:249 INFO] Running harness for bert benchmark in SingleStream scenario...
[2022-02-22 07:49:03,043 __init__.py:185 INFO] Running command: ./build/bin/harness_bert --logfile_outdir="/work/build/logs/2022.02.22-07.49.01/DGX-A100_A100-SXM-80GBx1_TRT/bert-99/SingleStream" --logfile_prefix="mlperf_log_" --performance_sample_count=10833 --test_mode="PerformanceOnly" --gpu_batch_size=1 --tensor_path="${PREPROCESSED_DATA_DIR}/squad_tokenized/input_ids.npy,${PREPROCESSED_DATA_DIR}/squad_tokenized/segment_ids.npy,${PREPROCESSED_DATA_DIR}/squad_tokenized/input_mask.npy" --use_graphs=true --gpu_inference_streams=1 --gpu_copy_streams=1 --single_stream_expected_latency_ns=1700000 --gpu_engines="./build/engines/A100-SXM-80GBx1/bert/SingleStream/bert-SingleStream-gpu-int8_S_384_B_1_P_1_vs.custom_k_99_MaxP.plan" --mlperf_conf_path="measurements/DGX-A100_A100-SXM-80GBx1_TRT/bert-99/SingleStream/mlperf.conf" --user_conf_path="measurements/DGX-A100_A100-SXM-80GBx1_TRT/bert-99/SingleStream/user.conf" --scenario SingleStream --model bert
[2022-02-22 07:49:03,043 __init__.py:191 INFO] Overriding Environment
benchmark : Benchmark.BERT
bert_opt_seqlen : 270
coalesced_tensor : True
enable_interleaved : False
gemm_plugin_fairshare_cache_size : 120
gpu_batch_size : 1
gpu_copy_streams : 1
gpu_inference_streams : 1
input_dtype : int32
input_format : linear
precision : int8
scenario : Scenario.SingleStream
single_stream_expected_latency_ns : 1700000
system : A100-SXM-80GBx1
tensor_path : ${PREPROCESSED_DATA_DIR}/squad_tokenized/input_ids.npy,${PREPROCESSED_DATA_DIR}/squad_tokenized/segment_ids.npy,${PREPROCESSED_DATA_DIR}/squad_tokenized/input_mask.npy
use_graphs : True
use_small_tile_gemm_plugin : False
config_name : A100-SXM-80GBx1_bert_SingleStream
config_ver : custom_k_99_MaxP
accuracy_level : 99%
optimization_level : plugin-enabled
inference_server : custom
system_id : A100-SXM-80GBx1
use_cpu : False
power_limit : None
cpu_freq : None
test_mode : PerformanceOnly
gpu_num_bundles : 2
log_dir : /work/build/logs/2022.02.22-07.49.01
&&&& RUNNING BERT_HARNESS # ./build/bin/harness_bert
I0222 07:49:03.108354  2363 main_bert.cc:146] Found 1 GPUs
I0222 07:49:03.484220  2363 bert_server.cc:182] Engine Path: ./build/engines/A100-SXM-80GBx1/bert/SingleStream/bert-SingleStream-gpu-int8_S_384_B_1_P_1_vs.custom_k_99_MaxP.plan
[I] [TRT] [MemUsageChange] Init CUDA: CPU +492, GPU +0, now: CPU 1709, GPU 1131 (MiB)
[I] [TRT] Loaded engine size: 597 MB
[I] [TRT] [MemUsageSnapshot] deserializeCudaEngine begin: CPU 1709 MiB, GPU 1131 MiB
[I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +748, GPU +316, now: CPU 2535, GPU 1809 (MiB)
[I] [TRT] [MemUsageChange] Init cuDNN: CPU +618, GPU +266, now: CPU 3153, GPU 2075 (MiB)
[I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +0, now: CPU 3153, GPU 2059 (MiB)
[I] [TRT] [MemUsageSnapshot] deserializeCudaEngine end: CPU 3153 MiB, GPU 2059 MiB
I0222 07:49:08.379307  2363 bert_server.cc:230] Engines Creation Completed
I0222 07:49:08.406273  2363 bert_server.cc:234] Use CUDA graphs
I0222 07:49:08.406654  2363 bert_core_vs.cc:274] Engine - Device Memory requirements: 2777088
I0222 07:49:08.406664  2363 bert_core_vs.cc:282] Engine - Number of Optimization Profiles: 1
I0222 07:49:08.406668  2363 bert_core_vs.cc:309] Engine - Profile 0 maxDims 384 Bmax=1 Smax=384
[I] [TRT] [MemUsageSnapshot] ExecutionContext creation begin: CPU 1958 MiB, GPU 2063 MiB
[I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 1958, GPU 2071 (MiB)
[I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 1958, GPU 2079 (MiB)
[I] [TRT] [MemUsageSnapshot] ExecutionContext creation end: CPU 2020 MiB, GPU 2433 MiB
I0222 07:49:08.444818  2363 bert_core_vs.cc:313] Setting Opt.Prof. to 0
I0222 07:49:08.444846  2363 bert_core_vs.cc:326] Context creation complete. Max supported batchSize: 1
I0222 07:49:08.444944  2363 bert_core_vs.cc:356] Setup complete
I0222 07:49:08.844046  2368 bert_core_vs.cc:256] Created 96 CUDA graphs
I0222 07:49:08.845995  2363 main_bert.cc:173] Starting running actual test.
I0222 07:59:09.648892  2363 main_bert.cc:179] Finished running actual test.
================================================
MLPerf Results Summary
================================================
SUT name : BERT SERVER
Scenario : SingleStream
Mode     : PerformanceOnly
90th percentile latency (ns) : 1606616
Result is : VALID
  Min duration satisfied : Yes
  Min queries satisfied : Yes
  Early stopping satisfied: Yes
Early Stopping Result:
 * Processed at least 64 queries (393495).
 * Would discard 38910 highest latency queries.
 * Early stopping 90th percentile estimate: 1607169
 * Early stopping 99th percentile estimate: 1800282

================================================
Additional Stats
================================================
QPS w/ loadgen overhead         : 655.82
QPS w/o loadgen overhead        : 659.92

Min latency (ns)                : 1377895
Max latency (ns)                : 3948220
Mean latency (ns)               : 1515346
50.00 percentile latency (ns)   : 1489880
90.00 percentile latency (ns)   : 1606616
95.00 percentile latency (ns)   : 1730668
97.00 percentile latency (ns)   : 1791490
99.00 percentile latency (ns)   : 1800211
99.90 percentile latency (ns)   : 1815972

================================================
Test Parameters Used
================================================
samples_per_query : 1
target_qps : 588.235
target_latency (ns): 0
max_async_queries : 1
min_duration (ms): 600000
max_duration (ms): 0
min_query_count : 1024
max_query_count : 0
qsl_rng_seed : 6655344265603136530
sample_index_rng_seed : 15863379492028895792
schedule_rng_seed : 12662793979680847247
accuracy_log_rng_seed : 0
accuracy_log_probability : 0
accuracy_log_sampling_target : 0
print_timestamps : 0
performance_issue_unique : 0
performance_issue_same : 0
performance_issue_same_index : 0
performance_sample_count : 10833

No warnings encountered during test.

No errors encountered during test.
[I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +0, now: CPU 2076, GPU 3177 (MiB)
[2022-02-22 07:59:10,196 main.py:304 INFO] Result: result_90.00_percentile_latency_ns: 1606616, Result is VALID

======================= Perf harness results: =======================

DGX-A100_A100-SXM-80GBx1_TRT-custom_k_99_MaxP-SingleStream:
    bert: result_90.00_percentile_latency_ns: 1606616, Result is VALID


======================= Accuracy results: =======================

DGX-A100_A100-SXM-80GBx1_TRT-custom_k_99_MaxP-SingleStream:
    bert: No accuracy results in PerformanceOnly mode.

round#2
[2022-02-22 07:59:11,169 __init__.py:185 INFO] Running command: CUDA_VISIBLE_ORDER=PCI_BUS_ID nvidia-smi --query-gpu=gpu_name,pci.device_id,uuid --format=csv
[2022-02-22 07:59:11,182 main.py:760 INFO] Detected System ID: A100-SXM-80GBx1
[2022-02-22 07:59:11,426 main.py:249 INFO] Running harness for bert benchmark in SingleStream scenario...
[2022-02-22 07:59:11,726 __init__.py:185 INFO] Running command: ./build/bin/harness_bert --logfile_outdir="/work/build/logs/2022.02.22-07.59.10/DGX-A100_A100-SXM-80GBx1_TRT/bert-99/SingleStream" --logfile_prefix="mlperf_log_" --performance_sample_count=10833 --test_mode="PerformanceOnly" --gpu_batch_size=1 --tensor_path="${PREPROCESSED_DATA_DIR}/squad_tokenized/input_ids.npy,${PREPROCESSED_DATA_DIR}/squad_tokenized/segment_ids.npy,${PREPROCESSED_DATA_DIR}/squad_tokenized/input_mask.npy" --use_graphs=true --gpu_inference_streams=1 --gpu_copy_streams=1 --single_stream_expected_latency_ns=1700000 --gpu_engines="./build/engines/A100-SXM-80GBx1/bert/SingleStream/bert-SingleStream-gpu-int8_S_384_B_1_P_1_vs.custom_k_99_MaxP.plan" --mlperf_conf_path="measurements/DGX-A100_A100-SXM-80GBx1_TRT/bert-99/SingleStream/mlperf.conf" --user_conf_path="measurements/DGX-A100_A100-SXM-80GBx1_TRT/bert-99/SingleStream/user.conf" --scenario SingleStream --model bert
[2022-02-22 07:59:11,726 __init__.py:191 INFO] Overriding Environment
benchmark : Benchmark.BERT
bert_opt_seqlen : 270
coalesced_tensor : True
enable_interleaved : False
gemm_plugin_fairshare_cache_size : 120
gpu_batch_size : 1
gpu_copy_streams : 1
gpu_inference_streams : 1
input_dtype : int32
input_format : linear
precision : int8
scenario : Scenario.SingleStream
single_stream_expected_latency_ns : 1700000
system : A100-SXM-80GBx1
tensor_path : ${PREPROCESSED_DATA_DIR}/squad_tokenized/input_ids.npy,${PREPROCESSED_DATA_DIR}/squad_tokenized/segment_ids.npy,${PREPROCESSED_DATA_DIR}/squad_tokenized/input_mask.npy
use_graphs : True
use_small_tile_gemm_plugin : False
config_name : A100-SXM-80GBx1_bert_SingleStream
config_ver : custom_k_99_MaxP
accuracy_level : 99%
optimization_level : plugin-enabled
inference_server : custom
system_id : A100-SXM-80GBx1
use_cpu : False
power_limit : None
cpu_freq : None
test_mode : PerformanceOnly
gpu_num_bundles : 2
log_dir : /work/build/logs/2022.02.22-07.59.10
&&&& RUNNING BERT_HARNESS # ./build/bin/harness_bert
I0222 07:59:11.785768  2488 main_bert.cc:146] Found 1 GPUs
I0222 07:59:12.054577  2488 bert_server.cc:182] Engine Path: ./build/engines/A100-SXM-80GBx1/bert/SingleStream/bert-SingleStream-gpu-int8_S_384_B_1_P_1_vs.custom_k_99_MaxP.plan
[I] [TRT] [MemUsageChange] Init CUDA: CPU +492, GPU +0, now: CPU 1709, GPU 1131 (MiB)
[I] [TRT] Loaded engine size: 597 MB
[I] [TRT] [MemUsageSnapshot] deserializeCudaEngine begin: CPU 1709 MiB, GPU 1131 MiB
[I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +748, GPU +316, now: CPU 2535, GPU 1809 (MiB)
[I] [TRT] [MemUsageChange] Init cuDNN: CPU +618, GPU +266, now: CPU 3153, GPU 2075 (MiB)
[I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +0, now: CPU 3153, GPU 2059 (MiB)
[I] [TRT] [MemUsageSnapshot] deserializeCudaEngine end: CPU 3153 MiB, GPU 2059 MiB
I0222 07:59:16.641772  2488 bert_server.cc:230] Engines Creation Completed
I0222 07:59:16.657424  2488 bert_server.cc:234] Use CUDA graphs
I0222 07:59:16.657816  2488 bert_core_vs.cc:274] Engine - Device Memory requirements: 2777088
I0222 07:59:16.657825  2488 bert_core_vs.cc:282] Engine - Number of Optimization Profiles: 1
I0222 07:59:16.657830  2488 bert_core_vs.cc:309] Engine - Profile 0 maxDims 384 Bmax=1 Smax=384
[I] [TRT] [MemUsageSnapshot] ExecutionContext creation begin: CPU 1958 MiB, GPU 2063 MiB
[I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 1958, GPU 2071 (MiB)
[I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 1958, GPU 2079 (MiB)
[I] [TRT] [MemUsageSnapshot] ExecutionContext creation end: CPU 2020 MiB, GPU 2433 MiB
I0222 07:59:16.696436  2488 bert_core_vs.cc:313] Setting Opt.Prof. to 0
I0222 07:59:16.696472  2488 bert_core_vs.cc:326] Context creation complete. Max supported batchSize: 1
I0222 07:59:16.696569  2488 bert_core_vs.cc:356] Setup complete
I0222 07:59:17.101560  2493 bert_core_vs.cc:256] Created 96 CUDA graphs
I0222 07:59:17.103513  2488 main_bert.cc:173] Starting running actual test.
I0222 08:09:17.936612  2488 main_bert.cc:179] Finished running actual test.
================================================
MLPerf Results Summary
================================================
SUT name : BERT SERVER
Scenario : SingleStream
Mode     : PerformanceOnly
90th percentile latency (ns) : 1607716
Result is : VALID
  Min duration satisfied : Yes
  Min queries satisfied : Yes
  Early stopping satisfied: Yes
Early Stopping Result:
 * Processed at least 64 queries (393510).
 * Would discard 38912 highest latency queries.
 * Early stopping 90th percentile estimate: 1608264
 * Early stopping 99th percentile estimate: 1799479

================================================
Additional Stats
================================================
QPS w/ loadgen overhead         : 655.85
QPS w/o loadgen overhead        : 659.90

Min latency (ns)                : 1385871
Max latency (ns)                : 8071440
Mean latency (ns)               : 1515374
50.00 percentile latency (ns)   : 1488220
90.00 percentile latency (ns)   : 1607716
95.00 percentile latency (ns)   : 1734422
97.00 percentile latency (ns)   : 1793633
99.00 percentile latency (ns)   : 1799398
99.90 percentile latency (ns)   : 1816708

================================================
Test Parameters Used
================================================
samples_per_query : 1
target_qps : 588.235
target_latency (ns): 0
max_async_queries : 1
min_duration (ms): 600000
max_duration (ms): 0
min_query_count : 1024
max_query_count : 0
qsl_rng_seed : 6655344265603136530
sample_index_rng_seed : 15863379492028895792
schedule_rng_seed : 12662793979680847247
accuracy_log_rng_seed : 0
accuracy_log_probability : 0
accuracy_log_sampling_target : 0
print_timestamps : 0
performance_issue_unique : 0
performance_issue_same : 0
performance_issue_same_index : 0
performance_sample_count : 10833

No warnings encountered during test.

No errors encountered during test.
[I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +0, now: CPU 2076, GPU 3177 (MiB)
[2022-02-22 08:09:18,516 main.py:304 INFO] Result: result_90.00_percentile_latency_ns: 1607716, Result is VALID

======================= Perf harness results: =======================

DGX-A100_A100-SXM-80GBx1_TRT-custom_k_99_MaxP-SingleStream:
    bert: result_90.00_percentile_latency_ns: 1607716, Result is VALID


======================= Accuracy results: =======================

DGX-A100_A100-SXM-80GBx1_TRT-custom_k_99_MaxP-SingleStream:
    bert: No accuracy results in PerformanceOnly mode.

round#3
[2022-02-22 08:09:19,442 __init__.py:185 INFO] Running command: CUDA_VISIBLE_ORDER=PCI_BUS_ID nvidia-smi --query-gpu=gpu_name,pci.device_id,uuid --format=csv
[2022-02-22 08:09:19,455 main.py:760 INFO] Detected System ID: A100-SXM-80GBx1
[2022-02-22 08:09:19,703 main.py:249 INFO] Running harness for bert benchmark in SingleStream scenario...
[2022-02-22 08:09:19,994 __init__.py:185 INFO] Running command: ./build/bin/harness_bert --logfile_outdir="/work/build/logs/2022.02.22-08.09.18/DGX-A100_A100-SXM-80GBx1_TRT/bert-99/SingleStream" --logfile_prefix="mlperf_log_" --performance_sample_count=10833 --test_mode="PerformanceOnly" --gpu_batch_size=1 --tensor_path="${PREPROCESSED_DATA_DIR}/squad_tokenized/input_ids.npy,${PREPROCESSED_DATA_DIR}/squad_tokenized/segment_ids.npy,${PREPROCESSED_DATA_DIR}/squad_tokenized/input_mask.npy" --use_graphs=true --gpu_inference_streams=1 --gpu_copy_streams=1 --single_stream_expected_latency_ns=1700000 --gpu_engines="./build/engines/A100-SXM-80GBx1/bert/SingleStream/bert-SingleStream-gpu-int8_S_384_B_1_P_1_vs.custom_k_99_MaxP.plan" --mlperf_conf_path="measurements/DGX-A100_A100-SXM-80GBx1_TRT/bert-99/SingleStream/mlperf.conf" --user_conf_path="measurements/DGX-A100_A100-SXM-80GBx1_TRT/bert-99/SingleStream/user.conf" --scenario SingleStream --model bert
[2022-02-22 08:09:19,994 __init__.py:191 INFO] Overriding Environment
benchmark : Benchmark.BERT
bert_opt_seqlen : 270
coalesced_tensor : True
enable_interleaved : False
gemm_plugin_fairshare_cache_size : 120
gpu_batch_size : 1
gpu_copy_streams : 1
gpu_inference_streams : 1
input_dtype : int32
input_format : linear
precision : int8
scenario : Scenario.SingleStream
single_stream_expected_latency_ns : 1700000
system : A100-SXM-80GBx1
tensor_path : ${PREPROCESSED_DATA_DIR}/squad_tokenized/input_ids.npy,${PREPROCESSED_DATA_DIR}/squad_tokenized/segment_ids.npy,${PREPROCESSED_DATA_DIR}/squad_tokenized/input_mask.npy
use_graphs : True
use_small_tile_gemm_plugin : False
config_name : A100-SXM-80GBx1_bert_SingleStream
config_ver : custom_k_99_MaxP
accuracy_level : 99%
optimization_level : plugin-enabled
inference_server : custom
system_id : A100-SXM-80GBx1
use_cpu : False
power_limit : None
cpu_freq : None
test_mode : PerformanceOnly
gpu_num_bundles : 2
log_dir : /work/build/logs/2022.02.22-08.09.18
&&&& RUNNING BERT_HARNESS # ./build/bin/harness_bert
I0222 08:09:20.050837  2613 main_bert.cc:146] Found 1 GPUs
I0222 08:09:20.328166  2613 bert_server.cc:182] Engine Path: ./build/engines/A100-SXM-80GBx1/bert/SingleStream/bert-SingleStream-gpu-int8_S_384_B_1_P_1_vs.custom_k_99_MaxP.plan
[I] [TRT] [MemUsageChange] Init CUDA: CPU +492, GPU +0, now: CPU 1709, GPU 1131 (MiB)
[I] [TRT] Loaded engine size: 597 MB
[I] [TRT] [MemUsageSnapshot] deserializeCudaEngine begin: CPU 1709 MiB, GPU 1131 MiB
[I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +748, GPU +316, now: CPU 2535, GPU 1809 (MiB)
[I] [TRT] [MemUsageChange] Init cuDNN: CPU +618, GPU +266, now: CPU 3153, GPU 2075 (MiB)
[I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +0, now: CPU 3153, GPU 2059 (MiB)
[I] [TRT] [MemUsageSnapshot] deserializeCudaEngine end: CPU 3153 MiB, GPU 2059 MiB
I0222 08:09:24.905035  2613 bert_server.cc:230] Engines Creation Completed
I0222 08:09:24.929121  2613 bert_server.cc:234] Use CUDA graphs
I0222 08:09:24.929515  2613 bert_core_vs.cc:274] Engine - Device Memory requirements: 2777088
I0222 08:09:24.929525  2613 bert_core_vs.cc:282] Engine - Number of Optimization Profiles: 1
I0222 08:09:24.929530  2613 bert_core_vs.cc:309] Engine - Profile 0 maxDims 384 Bmax=1 Smax=384
[I] [TRT] [MemUsageSnapshot] ExecutionContext creation begin: CPU 1958 MiB, GPU 2063 MiB
[I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 1958, GPU 2071 (MiB)
[I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 1958, GPU 2079 (MiB)
[I] [TRT] [MemUsageSnapshot] ExecutionContext creation end: CPU 2020 MiB, GPU 2433 MiB
I0222 08:09:24.968084  2613 bert_core_vs.cc:313] Setting Opt.Prof. to 0
I0222 08:09:24.968119  2613 bert_core_vs.cc:326] Context creation complete. Max supported batchSize: 1
I0222 08:09:24.968209  2613 bert_core_vs.cc:356] Setup complete
I0222 08:09:25.376802  2618 bert_core_vs.cc:256] Created 96 CUDA graphs
I0222 08:09:25.378769  2613 main_bert.cc:173] Starting running actual test.
I0222 08:19:26.215896  2613 main_bert.cc:179] Finished running actual test.
================================================
MLPerf Results Summary
================================================
SUT name : BERT SERVER
Scenario : SingleStream
Mode     : PerformanceOnly
90th percentile latency (ns) : 1607358
Result is : VALID
  Min duration satisfied : Yes
  Min queries satisfied : Yes
  Early stopping satisfied: Yes
Early Stopping Result:
 * Processed at least 64 queries (393637).
 * Would discard 38924 highest latency queries.
 * Early stopping 90th percentile estimate: 1608195
 * Early stopping 99th percentile estimate: 1798672

================================================
Additional Stats
================================================
QPS w/ loadgen overhead         : 656.06
QPS w/o loadgen overhead        : 660.16

Min latency (ns)                : 1379697
Max latency (ns)                : 8544935
Mean latency (ns)               : 1514785
50.00 percentile latency (ns)   : 1487790
90.00 percentile latency (ns)   : 1607358
95.00 percentile latency (ns)   : 1731300
97.00 percentile latency (ns)   : 1790793
99.00 percentile latency (ns)   : 1798443
99.90 percentile latency (ns)   : 1811198

================================================
Test Parameters Used
================================================
samples_per_query : 1
target_qps : 588.235
target_latency (ns): 0
max_async_queries : 1
min_duration (ms): 600000
max_duration (ms): 0
min_query_count : 1024
max_query_count : 0
qsl_rng_seed : 6655344265603136530
sample_index_rng_seed : 15863379492028895792
schedule_rng_seed : 12662793979680847247
accuracy_log_rng_seed : 0
accuracy_log_probability : 0
accuracy_log_sampling_target : 0
print_timestamps : 0
performance_issue_unique : 0
performance_issue_same : 0
performance_issue_same_index : 0
performance_sample_count : 10833

No warnings encountered during test.

No errors encountered during test.
[I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +0, now: CPU 2076, GPU 3177 (MiB)
[2022-02-22 08:19:26,769 main.py:304 INFO] Result: result_90.00_percentile_latency_ns: 1607358, Result is VALID

======================= Perf harness results: =======================

DGX-A100_A100-SXM-80GBx1_TRT-custom_k_99_MaxP-SingleStream:
    bert: result_90.00_percentile_latency_ns: 1607358, Result is VALID


======================= Accuracy results: =======================

DGX-A100_A100-SXM-80GBx1_TRT-custom_k_99_MaxP-SingleStream:
    bert: No accuracy results in PerformanceOnly mode.

round#4
[2022-02-22 08:19:27,738 __init__.py:185 INFO] Running command: CUDA_VISIBLE_ORDER=PCI_BUS_ID nvidia-smi --query-gpu=gpu_name,pci.device_id,uuid --format=csv
[2022-02-22 08:19:27,756 main.py:760 INFO] Detected System ID: A100-SXM-80GBx1
[2022-02-22 08:19:28,000 main.py:249 INFO] Running harness for bert benchmark in SingleStream scenario...
[2022-02-22 08:19:28,285 __init__.py:185 INFO] Running command: ./build/bin/harness_bert --logfile_outdir="/work/build/logs/2022.02.22-08.19.27/DGX-A100_A100-SXM-80GBx1_TRT/bert-99/SingleStream" --logfile_prefix="mlperf_log_" --performance_sample_count=10833 --test_mode="PerformanceOnly" --gpu_batch_size=1 --tensor_path="${PREPROCESSED_DATA_DIR}/squad_tokenized/input_ids.npy,${PREPROCESSED_DATA_DIR}/squad_tokenized/segment_ids.npy,${PREPROCESSED_DATA_DIR}/squad_tokenized/input_mask.npy" --use_graphs=true --gpu_inference_streams=1 --gpu_copy_streams=1 --single_stream_expected_latency_ns=1700000 --gpu_engines="./build/engines/A100-SXM-80GBx1/bert/SingleStream/bert-SingleStream-gpu-int8_S_384_B_1_P_1_vs.custom_k_99_MaxP.plan" --mlperf_conf_path="measurements/DGX-A100_A100-SXM-80GBx1_TRT/bert-99/SingleStream/mlperf.conf" --user_conf_path="measurements/DGX-A100_A100-SXM-80GBx1_TRT/bert-99/SingleStream/user.conf" --scenario SingleStream --model bert
[2022-02-22 08:19:28,285 __init__.py:191 INFO] Overriding Environment
benchmark : Benchmark.BERT
bert_opt_seqlen : 270
coalesced_tensor : True
enable_interleaved : False
gemm_plugin_fairshare_cache_size : 120
gpu_batch_size : 1
gpu_copy_streams : 1
gpu_inference_streams : 1
input_dtype : int32
input_format : linear
precision : int8
scenario : Scenario.SingleStream
single_stream_expected_latency_ns : 1700000
system : A100-SXM-80GBx1
tensor_path : ${PREPROCESSED_DATA_DIR}/squad_tokenized/input_ids.npy,${PREPROCESSED_DATA_DIR}/squad_tokenized/segment_ids.npy,${PREPROCESSED_DATA_DIR}/squad_tokenized/input_mask.npy
use_graphs : True
use_small_tile_gemm_plugin : False
config_name : A100-SXM-80GBx1_bert_SingleStream
config_ver : custom_k_99_MaxP
accuracy_level : 99%
optimization_level : plugin-enabled
inference_server : custom
system_id : A100-SXM-80GBx1
use_cpu : False
power_limit : None
cpu_freq : None
test_mode : PerformanceOnly
gpu_num_bundles : 2
log_dir : /work/build/logs/2022.02.22-08.19.27
&&&& RUNNING BERT_HARNESS # ./build/bin/harness_bert
I0222 08:19:28.345515  2738 main_bert.cc:146] Found 1 GPUs
I0222 08:19:28.617996  2738 bert_server.cc:182] Engine Path: ./build/engines/A100-SXM-80GBx1/bert/SingleStream/bert-SingleStream-gpu-int8_S_384_B_1_P_1_vs.custom_k_99_MaxP.plan
[I] [TRT] [MemUsageChange] Init CUDA: CPU +492, GPU +0, now: CPU 1709, GPU 1131 (MiB)
[I] [TRT] Loaded engine size: 597 MB
[I] [TRT] [MemUsageSnapshot] deserializeCudaEngine begin: CPU 1709 MiB, GPU 1131 MiB
[I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +748, GPU +316, now: CPU 2535, GPU 1809 (MiB)
[I] [TRT] [MemUsageChange] Init cuDNN: CPU +618, GPU +266, now: CPU 3153, GPU 2075 (MiB)
[I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +0, now: CPU 3153, GPU 2059 (MiB)
[I] [TRT] [MemUsageSnapshot] deserializeCudaEngine end: CPU 3153 MiB, GPU 2059 MiB
I0222 08:19:33.181636  2738 bert_server.cc:230] Engines Creation Completed
I0222 08:19:33.197554  2738 bert_server.cc:234] Use CUDA graphs
I0222 08:19:33.197937  2738 bert_core_vs.cc:274] Engine - Device Memory requirements: 2777088
I0222 08:19:33.197945  2738 bert_core_vs.cc:282] Engine - Number of Optimization Profiles: 1
I0222 08:19:33.197950  2738 bert_core_vs.cc:309] Engine - Profile 0 maxDims 384 Bmax=1 Smax=384
[I] [TRT] [MemUsageSnapshot] ExecutionContext creation begin: CPU 1958 MiB, GPU 2063 MiB
[I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 1958, GPU 2071 (MiB)
[I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 1958, GPU 2079 (MiB)
[I] [TRT] [MemUsageSnapshot] ExecutionContext creation end: CPU 2020 MiB, GPU 2433 MiB
I0222 08:19:33.236580  2738 bert_core_vs.cc:313] Setting Opt.Prof. to 0
I0222 08:19:33.236634  2738 bert_core_vs.cc:326] Context creation complete. Max supported batchSize: 1
I0222 08:19:33.236726  2738 bert_core_vs.cc:356] Setup complete
I0222 08:19:33.643689  2743 bert_core_vs.cc:256] Created 96 CUDA graphs
I0222 08:19:33.645640  2738 main_bert.cc:173] Starting running actual test.
Traceback (most recent call last):
  File "code/main.py", line 763, in <module>
    main(main_args, system)
  File "code/main.py", line 736, in main
    dispatch_action(main_args, config_dict, workload_id, equiv_engine_setting=equiv_engine_setting)
  File "code/main.py", line 572, in dispatch_action
    handle_run_harness(benchmark_conf, need_gpu, need_dla, profile, power)
  File "code/main.py", line 303, in handle_run_harness
    result = harness.run_harness()
  File "/work/code/common/harness.py", line 270, in run_harness
    output = run_command(cmd, get_output=True, custom_env=self.env_vars)
  File "/work/code/common/__init__.py", line 195, in run_command
    for line in iter(p.stdout.readline, b""):
KeyboardInterrupt
make: *** [Makefile:626: run_harness] Interrupt
